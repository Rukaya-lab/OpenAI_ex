{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15dyYouIMWba8ckDwzoOj187uo5ekxkUZ",
      "authorship_tag": "ABX9TyOt1J7mYyN7mDrUJ/bq2DEH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rukaya-lab/OpenAI_ex/blob/main/Quering_Multiple_PDF_from_Vector_Store_using_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28yD4rkGkPBX"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install langchain\n",
        "!pip install unstructured\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils\n",
        "\n",
        "!pip install pdf2image\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "eIoBikHnm63Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install glove"
      ],
      "metadata": {
        "id": "o6jRkvHT4fZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Helper Library\n"
      ],
      "metadata": {
        "id": "fYELdk1Ekb2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n"
      ],
      "metadata": {
        "id": "Di8YODkklfFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "GV0IhYuvkUuK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get your API keys from openai, you will need to create an account. \n",
        "# Here is the link to get the keys: https://platform.openai.com/account/billing/overview\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Use Your Open AI API Key\""
      ],
      "metadata": {
        "id": "qr_2MJj1kr-c"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get from drive\n",
        "\n",
        "root_dir = \"/content/drive/MyDrive/Original\""
      ],
      "metadata": {
        "id": "Lq9PPsvWk2wd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder_path = f'{root_dir}/'\n",
        "os.listdir(pdf_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aZdugdclXqM",
        "outputId": "67d2aa04-3b75-4618-bf75-9cd9fb4d2c21"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['VMD0036.pdf', 'VMD0037.pdf', 'VT0004.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location of the pdf file/files. \n",
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]"
      ],
      "metadata": {
        "id": "AGAKb5CclKC9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnZKzTtOmyRQ",
        "outputId": "adb9c618-eb2a-44ff-9429-e83159a24ed4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7fd471943700>,\n",
              " <langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7fd471943790>,\n",
              " <langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7fd470c2fc40>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Store as a Wrapper\n",
        "\n",
        "  Chroma as vectorstore to index and search embeddings\n",
        "\n",
        "  There are three main steps going on after the documents are loaded:\n",
        "\n",
        "  Splitting documents into chunks\n",
        "\n",
        "  Creating embeddings for each document\n",
        "\n",
        "  Storing documents and embeddings in a vectorstore\n",
        "\n",
        "\n",
        "### VectorstoreIndexCreator is just a wrapper around all this logic. \n",
        " It is simply this\n",
        "\n",
        "  \n",
        "\n",
        "```\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "      vectorstore_cls=Chroma, \n",
        "      embedding=OpenAIEmbeddings(),\n",
        "      text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "  )\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ix2DQlzbnAdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator().from_loaders(loaders)\n",
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Ouv0IgnexW",
        "outputId": "eb8474aa-fbf2-4bef-f83d-f16407ddb3ce"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd42895f910>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what are the applicability conditions\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "P4DyQmp_-apL",
        "outputId": "7b28f609-64cb-48f6-8bb1-b5cf4d9c85a8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This module is applicable to jurisdictional programs seeking to estimate a global commodity leakage value as referenced by the VCS JNR Leakage Tool. The module is applicable under the following conditions: jurisdictional proponent may follow the method to determine the area of production subject to leakage in accordance VCS module VMD0036 Global Commodity Leakage Module: Effective Area Approach or follow the method to determine the amount of production subject to leakage in accordance with VCS module VMD0037 Global Commodity Leakage Module: Production Approach, or justify an alternative method to demonstrate the jurisdictional program is substantially maintaining production. To qualify for mitigation criterion (b), provide evidence that the production of relevant domestic commodities is substantially maintained or that the jurisdictional program does not impact the production of relevant domestic commodities within the jurisdiction. To qualify for mitigation criterion (c), provide evidence that strategies, policies or measures to address subsistence drivers support and sustain alternative, non-deforesting and non-degrading livelihoods, and/or provide low-emission alternatives to agents of subsistence drivers within the jurisdiction.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Long Route\n",
        "\n",
        "Instead of using the vector store index creator wrapper"
      ],
      "metadata": {
        "id": "QyQHX5Wo-5ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "eYHrGr57rBba"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, we will split the documents into chunks.\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "8-LO_XAB-_86"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "rZKuFYXp_NR4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We now create the vectorstore to use as the index.\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "id": "b6kzXFHk_S8u"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#So thatâ€™s creating the index. Then, we expose this index in a retriever interface.\n",
        "\n",
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "_3QtwfpY_a8m"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create the chain to answer questions"
      ],
      "metadata": {
        "id": "0WgdHE0G_yBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n"
      ],
      "metadata": {
        "id": "tTW6OVQn_iU_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the analysis of leakage categories?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "KIcO1c-tAANp",
        "outputId": "29271318-07a8-4bdc-d9a7-6cc84de59873"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The analysis of leakage categories includes observed production for commodity j within the jurisdiction, proportion of leakage resulting in increased supply outside the jurisdiction, proportion of increased supply coming from new land brought into production, share of unaccounted leakage within the country, share of recent global deforestation (and degradation) emissions occurring within the country, share of global forest carbon stocks at-risk of deforestation (and degradation) existing within the country, amount of deforestation (and degradation) already accounted for by other jurisdictional REDD+ programs within the country, and average carbon stocks of forests within the country.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "Now we have been able to load multiple files from a folder, create a vector storage from chunks of the text in the files and the embeddings and then queried the vectors to retrieve answers.\n"
      ],
      "metadata": {
        "id": "Lr7nqWRRBDtl"
      }
    }
  ]
}