{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rukaya-lab/OpenAI_ex/blob/main/Quering_Multiple_PDF_from_Vector_Store_using_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**LangChain is an open-source framework designed for developing applications powered by a language model. It provides a number of features that make it easy to build and deploy**\n",
        "\n",
        "**applications that use language models, including:** \n",
        "\n",
        "    - A simple and intuitive API that makes it easy to interact with language models\n",
        "    - A number of pre-trained language models that can be used to power applications\n",
        "    - A number of tools and utilities that can be used to develop and deploy applications that use language models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The aim here is to levarage the PDF explorer module provide by langchain to access the PDF knowlege base and also the pipeline to query the documents and provide answers using** \n",
        "\n",
        "**openAI as the LLM.**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Dependent Modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28yD4rkGkPBX"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install langchain\n",
        "!pip install unstructured\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIoBikHnm63Y"
      },
      "outputs": [],
      "source": [
        "!apt-get install poppler-utils\n",
        "\n",
        "!pip install pdf2image\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6jRkvHT4fZz"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install glove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYELdk1Ekb2U"
      },
      "source": [
        "### Load Helper Library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di8YODkklfFe"
      },
      "outputs": [],
      "source": [
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GV0IhYuvkUuK"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qr_2MJj1kr-c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get your API keys from openai, you will need to create an account. \n",
        "# Here is the link to get the keys: https://platform.openai.com/account/billing/overview\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Use Your Open AI API Key\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the PDF files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Lq9PPsvWk2wd"
      },
      "outputs": [],
      "source": [
        "#get from drive\n",
        "\n",
        "root_dir = \"/content/drive/MyDrive/Original\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aZdugdclXqM",
        "outputId": "67d2aa04-3b75-4618-bf75-9cd9fb4d2c21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['VMD0036.pdf', 'VMD0037.pdf', 'VT0004.pdf']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_folder_path = f'{root_dir}/'\n",
        "os.listdir(pdf_folder_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert PDFs to document object. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AGAKb5CclKC9"
      },
      "outputs": [],
      "source": [
        "# location of the pdf file/files. \n",
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnZKzTtOmyRQ",
        "outputId": "adb9c618-eb2a-44ff-9429-e83159a24ed4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7fd471943700>,\n",
              " <langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7fd471943790>,\n",
              " <langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7fd470c2fc40>]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaders"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix2DQlzbnAdD"
      },
      "source": [
        "### Vector Store as a Wrapper\n",
        "\n",
        "Chroma as the vectorstore to index and search embeddings\n",
        "\n",
        "There are three main steps going on in the backgroundwhen the vectorstoreindex is used after the documents are loaded:\n",
        "\n",
        "    - Splitting documents into chunks\n",
        "\n",
        "    - Creating embeddings for each document\n",
        "\n",
        "    - Storing documents and embeddings in a vectorstore\n",
        "\n",
        "\n",
        "### VectorstoreIndexCreator is just a wrapper around all this logic. \n",
        " It is simply this\n",
        "  \n",
        "\n",
        "```\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "      vectorstore_cls=Chroma, \n",
        "      embedding=OpenAIEmbeddings(),\n",
        "      text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "  )\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Ouv0IgnexW",
        "outputId": "eb8474aa-fbf2-4bef-f83d-f16407ddb3ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7fd42895f910>)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index = VectorstoreIndexCreator().from_loaders(loaders)\n",
        "index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "P4DyQmp_-apL",
        "outputId": "7b28f609-64cb-48f6-8bb1-b5cf4d9c85a8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' This module is applicable to jurisdictional programs seeking to estimate a global commodity leakage value as referenced by the VCS JNR Leakage Tool. The module is applicable under the following conditions: jurisdictional proponent may follow the method to determine the area of production subject to leakage in accordance VCS module VMD0036 Global Commodity Leakage Module: Effective Area Approach or follow the method to determine the amount of production subject to leakage in accordance with VCS module VMD0037 Global Commodity Leakage Module: Production Approach, or justify an alternative method to demonstrate the jurisdictional program is substantially maintaining production. To qualify for mitigation criterion (b), provide evidence that the production of relevant domestic commodities is substantially maintained or that the jurisdictional program does not impact the production of relevant domestic commodities within the jurisdiction. To qualify for mitigation criterion (c), provide evidence that strategies, policies or measures to address subsistence drivers support and sustain alternative, non-deforesting and non-degrading livelihoods, and/or provide low-emission alternatives to agents of subsistence drivers within the jurisdiction.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"what are the applicability conditions\"\n",
        "index.query(query)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QyQHX5Wo-5ox"
      },
      "source": [
        "### Long Route\n",
        "Rather than usingthe Vector wrapper, you can explore each steps individually.\n",
        "\n",
        "Instead of using the vector store index creator wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "eYHrGr57rBba"
      },
      "outputs": [],
      "source": [
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8-LO_XAB-_86"
      },
      "outputs": [],
      "source": [
        "#Next, we will split the documents into chunks.\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Craete Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rZKuFYXp_NR4"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set up Indexes from Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "b6kzXFHk_S8u"
      },
      "outputs": [],
      "source": [
        "#We now create the vectorstore to use as the index.\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_3QtwfpY_a8m"
      },
      "outputs": [],
      "source": [
        "#So that’s creating the index. Then, we expose this index in a retriever interface.\n",
        "\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WgdHE0G_yBG"
      },
      "source": [
        "#### Create the chain to answer questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tTW6OVQn_iU_"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "KIcO1c-tAANp",
        "outputId": "29271318-07a8-4bdc-d9a7-6cc84de59873"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The analysis of leakage categories includes observed production for commodity j within the jurisdiction, proportion of leakage resulting in increased supply outside the jurisdiction, proportion of increased supply coming from new land brought into production, share of unaccounted leakage within the country, share of recent global deforestation (and degradation) emissions occurring within the country, share of global forest carbon stocks at-risk of deforestation (and degradation) existing within the country, amount of deforestation (and degradation) already accounted for by other jurisdictional REDD+ programs within the country, and average carbon stocks of forests within the country.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What are the analysis of leakage categories?\"\n",
        "qa.run(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr7nqWRRBDtl"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "Now we have been able to load multiple files from a folder, create a vector storage from chunks of the text in the files and the embeddings and then queried the vectors to retrieve answers.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next Steps\n",
        "- This task is tested with just a few PDF files, a larger number of files can be added.\n",
        "\n",
        "- Other forms of document storage like csv, excel, databases can be explored."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOt1J7mYyN7mDrUJ/bq2DEH",
      "include_colab_link": true,
      "mount_file_id": "15dyYouIMWba8ckDwzoOj187uo5ekxkUZ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
